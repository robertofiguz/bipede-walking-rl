{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2nl6h2ic) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 51632... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>episode_score</td><td>▁▃▄▄█</td></tr><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>epsilon</td><td>███████████████▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>loss</td><td>██▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>episode_score</td><td>33.8</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>epsilon</td><td>0.98628</td></tr><tr><td>loss</td><td>0.47423</td></tr></table>\n",
       "</div></div>\n",
       "Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">splendid-dawn-26</strong>: <a href=\"http://localhost:8080/sudofork/cartpole-v2/runs/2nl6h2ic\" target=\"_blank\">http://localhost:8080/sudofork/cartpole-v2/runs/2nl6h2ic</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220220_191832-2nl6h2ic/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Upgrade to the 0.9.48 version of W&B Local to get the latest features. Learn more: http://wandb.me/local-upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2nl6h2ic). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"http://localhost:8080/sudofork/cartpole-v2/runs/dygs8yq1\" target=\"_blank\">vivid-grass-27</a></strong> to <a href=\"http://localhost:8080/sudofork/cartpole-v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import logger\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "run = wandb.init(\n",
    "    config={\n",
    "        \"gamma\": 0.99, \n",
    "        \"epsilon\": 1,\n",
    "        \"epsilon_min\": 0.1,\n",
    "        \"target_reward\": 400.0,\n",
    "        \"batch_size\": 64,\n",
    "        \"win_trials\": 100,\n",
    "        \"units\": 256,\n",
    "        \"learning_rate\": 0.001\n",
    "        },\n",
    "    project=\"cartpole-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self,\n",
    "                 state_space, \n",
    "                 action_space, \n",
    "                 episodes=500):\n",
    "        \"\"\"DQN Agent on CartPole-v0 environment\n",
    "\n",
    "        Arguments:\n",
    "            state_space (tensor): state space\n",
    "            action_space (tensor): action space\n",
    "            episodes (int): number of episodes to train\n",
    "        \"\"\"\n",
    "        self.action_space = action_space\n",
    "\n",
    "        # experience buffer\n",
    "        self.memory = []\n",
    "\n",
    "        # discount rate\n",
    "        self.gamma = run.config.gamma\n",
    "\n",
    "        # initially 90% exploration, 10% exploitation\n",
    "        self.epsilon = run.config.epsilon\n",
    "        # iteratively applying decay til \n",
    "        # 10% exploration/90% exploitation\n",
    "        self.epsilon_min = run.config.epsilon_min\n",
    "        self.epsilon_decay = self.epsilon_min / self.epsilon\n",
    "        self.epsilon_decay = self.epsilon_decay ** \\\n",
    "                             (1. / float(episodes))\n",
    "\n",
    "        # Q Network weights filename\n",
    "        self.weights_file = 'dqn_cartpole.h5'\n",
    "        # Q Network for training\n",
    "        n_inputs = state_space.shape[0]\n",
    "        n_outputs = action_space.n\n",
    "        self.q_model = self.build_model(n_inputs, n_outputs)\n",
    "        self.q_model.compile(loss='mae', optimizer=Adam(learning_rate=run.config.learning_rate))\n",
    "        # target Q Network\n",
    "        self.target_q_model = self.build_model(n_inputs, n_outputs)\n",
    "        # copy Q Network params to target Q Network\n",
    "        self.update_weights()\n",
    "\n",
    "        self.replay_counter = 0\n",
    "\n",
    "    \n",
    "    def build_model(self, n_inputs, n_outputs):\n",
    "        inputs = Input(shape=(n_inputs, ), name='state')\n",
    "        x = Dense(run.config.units, activation='relu')(inputs)\n",
    "        x = Dense(run.config.units, activation='relu')(x)\n",
    "        x = Dense(run.config.units, activation='relu')(x)\n",
    "        x = Dense(n_outputs,\n",
    "                  activation='linear', \n",
    "                  name='action')(x)\n",
    "        q_model = Model(inputs, x)\n",
    "        q_model.summary()\n",
    "        return q_model\n",
    "\n",
    "\n",
    "    def save_weights(self):\n",
    "        \"\"\"save Q Network params to a file\"\"\"\n",
    "        self.q_model.save_weights(self.weights_file)\n",
    "\n",
    "\n",
    "    def update_weights(self):\n",
    "        \"\"\"copy trained Q Network params to target Q Network\"\"\"\n",
    "        self.target_q_model.set_weights(self.q_model.get_weights())\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"eps-greedy policy\n",
    "        Return:\n",
    "            action (tensor): action to execute\n",
    "        \"\"\"\n",
    "        run.log({\"epsilon\":self.epsilon})\n",
    "        if np.random.rand() < self.epsilon or episode_count<20:\n",
    "            # explore - do random action\n",
    "            return self.action_space.sample()\n",
    "        # exploit\n",
    "        q_values = self.q_model.predict(state)\n",
    "        # select the action with max Q-value\n",
    "        action = np.argmax(q_values[0])\n",
    "        return action\n",
    "\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"store experiences in the replay buffer\n",
    "        Arguments:\n",
    "            state (tensor): env state\n",
    "            action (tensor): agent action\n",
    "            reward (float): reward received after executing\n",
    "                action on state\n",
    "            next_state (tensor): next state\n",
    "        \"\"\"\n",
    "        item = (state, action, reward, next_state, done)\n",
    "        self.memory.append(item)\n",
    "\n",
    "\n",
    "    def get_target_q_value(self, next_state, reward):\n",
    "        \"\"\"compute Q_max\n",
    "           Use of target Q Network solves the \n",
    "            non-stationarity problem\n",
    "        Arguments:\n",
    "            reward (float): reward received after executing\n",
    "                action on state\n",
    "            next_state (tensor): next state\n",
    "        Return:\n",
    "            q_value (float): max Q-value computed\n",
    "        \"\"\"\n",
    "        # max Q value among next state's actions\n",
    "        # DQN chooses the max Q value among next actions\n",
    "        # selection and evaluation of action is \n",
    "        # on the target Q Network\n",
    "        # Q_max = max_a' Q_target(s', a')\n",
    "        q_value = np.amax(\\\n",
    "                     self.target_q_model.predict(next_state)[0])\n",
    "\n",
    "        # Q_max = reward + gamma * Q_max\n",
    "        q_value *= self.gamma\n",
    "        q_value += reward\n",
    "        return q_value\n",
    "\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"experience replay addresses the correlation issue \n",
    "            between samples\n",
    "        Arguments:\n",
    "            batch_size (int): replay buffer batch \n",
    "                sample size\n",
    "        \"\"\"\n",
    "        # sars = state, action, reward, state' (next_state)\n",
    "        sars_batch = random.sample(self.memory, batch_size)\n",
    "        state_batch, q_values_batch = [], []\n",
    "\n",
    "        # fixme: for speedup, this could be done on the tensor level\n",
    "        # but easier to understand using a loop\n",
    "        for state, action, reward, next_state, done in sars_batch:\n",
    "            # policy prediction for a given state\n",
    "            q_values = self.q_model.predict(state)\n",
    "            \n",
    "            # get Q_max\n",
    "            q_value = self.get_target_q_value(next_state, reward)\n",
    "\n",
    "            # correction on the Q value for the action used\n",
    "            q_values[0][action] = reward if done else q_value\n",
    "\n",
    "            # collect batch state-q_value mapping\n",
    "            state_batch.append(state[0])\n",
    "            q_values_batch.append(q_values[0])\n",
    "\n",
    "        # train the Q-network\n",
    "        self.q_model.fit(np.array(state_batch),\n",
    "                         np.array(q_values_batch),\n",
    "                         batch_size=batch_size,\n",
    "                         verbose=0,\n",
    "                         epochs=1,\n",
    "                         callbacks=WandbCallback())\n",
    "                \n",
    "\n",
    "        # update exploration-exploitation probability\n",
    "        self.update_epsilon()\n",
    "\n",
    "        # copy new params on old target after \n",
    "        # every 10 training updates\n",
    "        if self.replay_counter % 10 == 0:\n",
    "            self.update_weights()\n",
    "\n",
    "        self.replay_counter += 1\n",
    "\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        \"\"\"decrease the exploration, increase exploitation\"\"\"\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDQN Agent (Not in use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent(DQNAgent):\n",
    "    def __init__(self,\n",
    "                 state_space, \n",
    "                 action_space, \n",
    "                 episodes=500):\n",
    "        super().__init__(state_space, \n",
    "                         action_space, \n",
    "                         episodes)\n",
    "        \"\"\"DDQN Agent on CartPole-v0 environment\n",
    "\n",
    "        Arguments:\n",
    "            state_space (tensor): state space\n",
    "            action_space (tensor): action space\n",
    "            episodes (int): number of episodes to train\n",
    "        \"\"\"\n",
    "\n",
    "        # Q Network weights filename\n",
    "        self.weights_file = 'ddqn_cartpole.h5'\n",
    "        print(\"-------------DDQN------------\")\n",
    "\n",
    "    def get_target_q_value(self, next_state, reward):\n",
    "        \"\"\"compute Q_max\n",
    "           Use of target Q Network solves the \n",
    "            non-stationarity problem\n",
    "        Arguments:\n",
    "            reward (float): reward received after executing\n",
    "                action on state\n",
    "            next_state (tensor): next state\n",
    "        Returns:\n",
    "            q_value (float): max Q-value computed\n",
    "        \"\"\"\n",
    "        # max Q value among next state's actions\n",
    "        # DDQN\n",
    "        # current Q Network selects the action\n",
    "        # a'_max = argmax_a' Q(s', a')\n",
    "        action = np.argmax(self.q_model.predict(next_state)[0])\n",
    "        # target Q Network evaluates the action\n",
    "        # Q_max = Q_target(s', a'_max)\n",
    "        q_value = self.target_q_model.predict(\\\n",
    "                                      next_state)[0][action]\n",
    "\n",
    "        # Q_max = reward + gamma * Q_max\n",
    "        q_value *= self.gamma\n",
    "        q_value += reward\n",
    "        return q_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " state (InputLayer)          [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 256)               1280      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " action (Dense)              (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,378\n",
      "Trainable params: 133,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " state (InputLayer)          [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 256)               1280      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " action (Dense)              (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,378\n",
      "Trainable params: 133,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "22.0\n",
      "30.0\n",
      "14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 19:19:08.778898: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-20 19:19:08.816277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-20 19:19:11.130746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "22.0\n",
      "12.0\n",
      "43.0\n",
      "34.0\n",
      "29.0\n",
      "25.0\n",
      "34.0\n",
      "25.0\n",
      "13.0\n",
      "16.0\n",
      "21.0\n",
      "25.0\n",
      "28.0\n",
      "20.0\n",
      "18.0\n",
      "20.0\n",
      "17.0\n",
      "24.0\n",
      "29.0\n",
      "14.0\n",
      "12.0\n",
      "14.0\n",
      "13.0\n",
      "22.0\n",
      "15.0\n",
      "19.0\n",
      "12.0\n",
      "25.0\n",
      "9.0\n",
      "15.0\n",
      "15.0\n",
      "27.0\n",
      "13.0\n",
      "18.0\n",
      "12.0\n",
      "23.0\n",
      "21.0\n",
      "15.0\n",
      "17.0\n",
      "22.0\n",
      "14.0\n",
      "17.0\n",
      "12.0\n",
      "10.0\n",
      "11.0\n",
      "21.0\n",
      "13.0\n",
      "10.0\n",
      "16.0\n",
      "14.0\n",
      "14.0\n",
      "12.0\n",
      "17.0\n",
      "16.0\n",
      "14.0\n",
      "10.0\n",
      "12.0\n",
      "14.0\n",
      "10.0\n",
      "13.0\n",
      "17.0\n",
      "12.0\n",
      "22.0\n",
      "13.0\n",
      "12.0\n",
      "21.0\n",
      "13.0\n",
      "8.0\n",
      "11.0\n",
      "9.0\n",
      "17.0\n",
      "18.0\n",
      "12.0\n",
      "8.0\n",
      "11.0\n",
      "23.0\n",
      "16.0\n",
      "10.0\n",
      "13.0\n",
      "16.0\n",
      "11.0\n",
      "28.0\n",
      "24.0\n",
      "12.0\n",
      "19.0\n",
      "12.0\n",
      "11.0\n",
      "12.0\n",
      "17.0\n",
      "19.0\n",
      "15.0\n",
      "10.0\n",
      "11.0\n",
      "13.0\n",
      "16.0\n",
      "15.0\n",
      "Episode 100: Mean survival =                    16.83 in 100 episodes\n",
      "14.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "31.0\n",
      "11.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "16.0\n",
      "10.0\n",
      "16.0\n",
      "19.0\n",
      "18.0\n",
      "26.0\n",
      "13.0\n",
      "12.0\n",
      "16.0\n",
      "11.0\n",
      "16.0\n",
      "17.0\n",
      "11.0\n",
      "17.0\n",
      "29.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "15.0\n",
      "14.0\n",
      "9.0\n",
      "11.0\n",
      "19.0\n",
      "16.0\n",
      "15.0\n",
      "17.0\n",
      "27.0\n",
      "15.0\n",
      "14.0\n",
      "13.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "12.0\n",
      "9.0\n",
      "12.0\n",
      "13.0\n",
      "11.0\n",
      "10.0\n",
      "15.0\n",
      "14.0\n",
      "12.0\n",
      "10.0\n",
      "13.0\n",
      "12.0\n",
      "14.0\n",
      "11.0\n",
      "10.0\n",
      "14.0\n",
      "11.0\n",
      "11.0\n",
      "12.0\n",
      "12.0\n",
      "13.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "15.0\n",
      "11.0\n",
      "13.0\n",
      "10.0\n",
      "13.0\n",
      "13.0\n",
      "13.0\n",
      "14.0\n",
      "14.0\n",
      "11.0\n",
      "13.0\n",
      "8.0\n",
      "11.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "11.0\n",
      "11.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "12.0\n",
      "14.0\n",
      "9.0\n",
      "23.0\n",
      "13.0\n",
      "9.0\n",
      "9.0\n",
      "13.0\n",
      "Episode 200: Mean survival =                    12.86 in 100 episodes\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "11.0\n",
      "18.0\n",
      "9.0\n",
      "13.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "21.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "12.0\n",
      "10.0\n",
      "12.0\n",
      "12.0\n",
      "9.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "15.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "13.0\n",
      "13.0\n",
      "13.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "13.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "12.0\n",
      "9.0\n",
      "10.0\n",
      "16.0\n",
      "9.0\n",
      "8.0\n",
      "10.0\n",
      "14.0\n",
      "14.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "12.0\n",
      "9.0\n",
      "8.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "9.0\n",
      "17.0\n",
      "11.0\n",
      "11.0\n",
      "12.0\n",
      "9.0\n",
      "14.0\n",
      "10.0\n",
      "13.0\n",
      "12.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "15.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "13.0\n",
      "10.0\n",
      "9.0\n",
      "Episode 300: Mean survival =                    10.93 in 100 episodes\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "13.0\n",
      "15.0\n",
      "14.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "12.0\n",
      "11.0\n",
      "9.0\n",
      "17.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "16.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "16.0\n",
      "11.0\n",
      "12.0\n",
      "12.0\n",
      "12.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "9.0\n",
      "18.0\n",
      "10.0\n",
      "13.0\n",
      "12.0\n",
      "11.0\n",
      "10.0\n",
      "12.0\n",
      "12.0\n",
      "11.0\n",
      "11.0\n",
      "9.0\n",
      "13.0\n",
      "14.0\n",
      "13.0\n",
      "11.0\n",
      "12.0\n",
      "11.0\n",
      "9.0\n",
      "14.0\n",
      "9.0\n",
      "14.0\n",
      "10.0\n",
      "9.0\n",
      "13.0\n",
      "14.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "12.0\n",
      "9.0\n",
      "13.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "13.0\n",
      "14.0\n",
      "9.0\n",
      "13.0\n",
      "11.0\n",
      "8.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "18.0\n",
      "Episode 400: Mean survival =                    11.01 in 100 episodes\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "9.0\n",
      "8.0\n",
      "12.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "13.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "11.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "11.0\n",
      "14.0\n",
      "9.0\n",
      "9.0\n",
      "8.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "11.0\n",
      "13.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "Episode 500: Mean survival =                    10.07 in 100 episodes\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "9.0\n",
      "12.0\n",
      "11.0\n",
      "9.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "11.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "14.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "11.0\n",
      "11.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "13.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Episode 600: Mean survival =                    9.87 in 100 episodes\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "8.0\n",
      "11.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "14.0\n",
      "11.0\n",
      "10.0\n",
      "8.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "8.0\n",
      "12.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "8.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "17.0\n",
      "10.0\n",
      "Episode 700: Mean survival =                    9.76 in 100 episodes\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "14.0\n",
      "9.0\n",
      "10.0\n",
      "13.0\n",
      "10.0\n",
      "11.0\n",
      "14.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "8.0\n",
      "10.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "17.0\n",
      "9.0\n",
      "13.0\n",
      "12.0\n",
      "11.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "11.0\n",
      "10.0\n",
      "8.0\n",
      "11.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "8.0\n",
      "13.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "Episode 800: Mean survival =                    10.03 in 100 episodes\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "12.0\n",
      "9.0\n",
      "8.0\n",
      "8.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "11.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "13.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "12.0\n",
      "8.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "9.0\n",
      "14.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "12.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "Episode 900: Mean survival =                    9.84 in 100 episodes\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n",
      "12.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "8.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "10.0\n",
      "9.0\n",
      "12.0\n",
      "11.0\n",
      "8.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "10.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "9.0\n",
      "11.0\n",
      "9.0\n",
      "11.0\n",
      "10.0\n",
      "11.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING GPU stats error Command '['/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/bin/apple_gpu_stats', '--json']' died with <Signals.SIGINT: 2>.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/b96_459s33nd4p6h1wtmb6140000gn/T/ipykernel_43779/3719502219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# call experience relay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/nh/b96_459s33nd4p6h1wtmb6140000gn/T/ipykernel_43779/3305703650.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msars_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# policy prediction for a given state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# get Q_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1756\u001b[0m               stacklevel=2)\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1759\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1154\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     dataset = tf.data.Dataset.zip((\n\u001b[1;32m    352\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     ))\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    699\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \"\"\"\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m   4643\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4644\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4645\u001b[0;31m     variant_tensor = gen_dataset_ops.tensor_dataset(\n\u001b[0m\u001b[1;32m   4646\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4647\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mtensor_dataset\u001b[0;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   7371\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7372\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7373\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   7374\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TensorDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7375\u001b[0m         output_shapes, \"metadata\", metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    # the number of trials without falling over\n",
    "    win_trials = run.config.win_trials\n",
    "    # the CartPole-v0 is considered solved if \n",
    "    # for 100 consecutive trials, he cart pole has not \n",
    "    # fallen over and it has achieved an average \n",
    "    # reward of 195.0 \n",
    "    # a reward of +1 is provided for every timestep \n",
    "    # the pole remains upright\n",
    "    win_reward = { 'CartPole-v1' : run.config.target_reward }\n",
    "\n",
    "    # stores the reward per episode\n",
    "    scores = deque(maxlen=win_trials)\n",
    "    rewards_history_full = []\n",
    "    logger.setLevel(logger.ERROR)\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "    #env.seed(0)\n",
    "\n",
    "    # instantiate the DQN/DDQN agent\n",
    "\n",
    "    agent = DQNAgent(env.observation_space, env.action_space)\n",
    "\n",
    "    # should be solved in this number of episodes\n",
    "    episode_count = 3000\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    batch_size = run.config.batch_size\n",
    "\n",
    "    # by default, CartPole-v1 has max episode steps = 500\n",
    "    # you can use this to experiment beyond 500\n",
    "    # env._max_episode_steps = 4000\n",
    "\n",
    "    # Q-Learning sampling and fitting\n",
    "    for episode in range(episode_count):\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            # in CartPole-v0, action=0 is left and action=1 is right\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            #env.render()\n",
    "            # in CartPole-v0:\n",
    "            # state = [pos, vel, theta, angular speed]\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # store every experience unit in replay buffer\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        rewards_history_full.append(total_reward)\n",
    "        print(total_reward)\n",
    "        # call experience relay\n",
    "        if len(agent.memory) >= batch_size:\n",
    "            agent.replay(batch_size)\n",
    "    \n",
    "        scores.append(total_reward)\n",
    "        mean_score = np.mean(scores)\n",
    "        run.log({\"episode_score\": mean_score})\n",
    "        if mean_score >= win_reward[\"CartPole-v1\"] \\\n",
    "                and episode >= win_trials:\n",
    "            print(\"Solved in episode %d: \\\n",
    "                   Mean survival = %0.2lf in %d episodes\"\n",
    "                  % (episode, mean_score, win_trials))\n",
    "            print(\"Epsilon: \", agent.epsilon)\n",
    "            agent.save_weights()\n",
    "            break\n",
    "        if (episode + 1) % win_trials == 0:\n",
    "            print(\"Episode %d: Mean survival = \\\n",
    "                   %0.2lf in %d episodes\" %\n",
    "                  ((episode + 1), mean_score, win_trials))\n",
    "\n",
    "    # close the env and write monitor result info to disk\n",
    "  #  artifact = wandb.Artifact(\"weights_v1\", \"weights\")\n",
    "  #  artifact.add_file(\"dqn_cartpole.h5\")\n",
    "  #  run.log_artifact(artifact)\n",
    "    run.finish()\n",
    "    env.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xtuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.0\n",
      "236.0\n",
      "198.0\n",
      "206.0\n",
      "209.0\n",
      "320.0\n",
      "263.0\n",
      "202.0\n",
      "265.0\n",
      "262.0\n",
      "202.0\n",
      "213.0\n",
      "233.0\n",
      "310.0\n",
      "253.0\n",
      "227.0\n",
      "225.0\n",
      "211.0\n",
      "254.0\n",
      "198.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2e399b700>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(20):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    reward_epi = 0\n",
    "    while not done:\n",
    "        state_tensor = tf.convert_to_tensor(state)\n",
    "        state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "        q_values = agent.q_model.predict(state_tensor)\n",
    "        action = np.argmax(q_values[0])\n",
    "        state, reward, done, info = env.step(action)\n",
    "        reward_epi += reward\n",
    "        env.render()\n",
    "    print(reward_epi)\n",
    "plt.plot(rewards_history_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/b96_459s33nd4p6h1wtmb6140000gn/T/ipykernel_43779/1229890502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1783\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         self._steps_per_execution.numpy().item() > self._inferred_steps)\n\u001b[0;32m-> 1210\u001b[0;31m     \u001b[0moriginal_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_truncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 148, in check_network_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 125, in communicate_network_status\n",
      "    resp = self._communicate_network_status(status)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 388, in _communicate_network_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 166, in check_status\n",
      "    status_response = self._interface.communicate_stop_status()\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 114, in communicate_stop_status\n",
      "    resp = self._communicate_stop_status(status)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 378, in _communicate_stop_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/Users/roberto/miniforge3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    }
   ],
   "source": [
    "agent.q_model.load_weights('/Users/roberto/Projects/final_project/cartpole/dqn_cartpole.h5')\n",
    "for i in range(20):\n",
    "    state = env.reset()\n",
    "    for i in range(200):\n",
    "        env.render()\n",
    "        state =  np.reshape(state, [1, state_size])\n",
    "        action = np.argmax(agent.q_model.predict(state)[0])\n",
    "        state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a131500f6664666dd459dcc63d270fb7b4d21f27357580e425cf19c89539d686"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
