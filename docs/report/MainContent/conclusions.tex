\chapter{Conclusion}
Although the project's main target wasn't achieved, many objectives were successful. A 2D simulator and a 3D implementation of OpenAI Gym and ROS2 were achieved. Along with this, documentation produced shows what problems were faced and how these were mitigated, including training using Google colab, installing openai\_ros2 in the team's environment and mistakes to avoid, such as developing a reward function with a big focus on penalties. 

Starting with a simple environment such as the CartPole was good for the future of the project as it allowed for developing and testing the code in an already tested environment. It also allowed for experimentation with hyperparameters and strategies without wasting a lot of time in training. 

Developing the 2D Walker was a complex task due to the novelty of using new tools such as pymunk and pygame. Pymunk proved to be a good choice for the implementation as it is well documented, easy to use and allows for rendering directly without code duplication in pygame.

The training duration and computational power were the most limiting factors in developing this project. To achieve an optimal policy, it is clear that more and longer runs are required for testing hyperparameters and reward function variations.

A working implementation using openai\_ros2 was achieved and is ready for testing using a learning algorithm for future research.