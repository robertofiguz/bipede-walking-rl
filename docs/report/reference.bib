%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Roberto Figueiredo at 2022-03-30 19:54:35 +0100

 @misc{apple-tf,
  title        = {Tensorflow Plugin - Metal},
  url          = {https://developer.apple.com/metal/},
  howpublished = {\url{https://developer.apple.com/metal/tensorflow-plugin}},
  abstractnote = {Find presentations, documentation, sample code, and resources for building macOS, iOS, and tvOS apps with the Metal framework.},
  journal      = {Apple Developer},
  author       = {Inc, Apple},
  language     = {en},
  note         = {last visited: 2022-04-12}
}
@misc{atlas_rl,
  title        = {Deep Q-Learning for Humanoid Walking},
  abstractnote = {Existing methods to allow humanoid robots to walk suffer from a lack of adaptability to new and unexpected environments, due to their reliance on using only higher-level motion control with relatively fixed sub-motions, such as taking an individual step. These conventional methods require significant knowledge of controls and assumptions about the expected surroundings. Humans, however, manage to walk very efficiently and adapt to new environments well due to the learned behaviors. Our approach is to create a reinforcement learning framework that continuously chooses an action to perform, by utilizing a neural network to rate a set of joint values based on the current state of the robot. We successfully train the Boston Dynamics Atlas robot to learn how to walk with this framework.},
  publisher    = {Worcester Polytechnic Institute},
  author       = {Thompson, Alec Jeffrey and George, Nathan Drew},
  year         = {2016},
  month        = {Apr}
}

 @article{boldhearts,
  title        = {Bold Hearts Team Description for RoboCup 2019 (Humanoid Kid Size League)},
  url          = {http://arxiv.org/abs/1904.10066},
  abstractnote = {We participated in the RoboCup 2018 competition in Montreal with our newly developed BoldBot based on the Darwin-OP and mostly self-printed custom parts. This paper is about the lessons learnt from that competition and further developments for the RoboCup 2019 competition. Firstly, we briefly introduce the team along with an overview of past achievements. We then present a simple, standalone 2D simulator we use for simplifying the entry for new members with making basic RoboCup concepts quickly accessible. We describe our approach for semantic-segmentation for our vision used in the 2018 competition, which replaced the lookup-table (LUT) implementation we had before. We also discuss the extra structural support we plan to add to the printed parts of the BoldBot and our transition to ROS 2 as our new middleware. Lastly, we will present a collection of open-source contributions of our team.},
  note         = {arXiv: 1904.10066},
  journal      = {arXiv:1904.10066 [cs]},
  author       = {Scheunemann, Marcus M. and van Dijk, Sander G. and Miko, Rebecca and Barry, Daniel and Evans, George M. and Rossi, Alessandra and Polani, Daniel},
  year         = {2019},
  month        = {Apr}
}
 @misc{cartpole,
  author        = {OpenAI},
  date-modified = {2022-03-09 20:54:46 +0000},
  howpublished  = {\url{https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py}},
  keywords      = {cartpole, openai, gym},
  title         = {Cartpole},
  year          = {2016},
  note         = {last visited: 2022-04-22}
}
 @misc{chipmunk,
  author        = {Chipmunk},
  date-modified = {2022-03-09 20:54:46 +0000},
  howpublished  = {\url{http://chipmunk-physics.net}},
  keywords      = {2d, pymunk, physics},
  title         = {Chipmunk},
  note         = {last visited: 2020-03-10}
}

@misc{empowerment,
  title        = {Empowerment driven Exploration},
  url          = {http://navneet-nmk.github.io/2018-08-26-empowerment/},
  abstractnote = {Empowerment as intrinsic reward},
  author       = {Kumar, Navneet Madhu},
  language     = {en},
  note         = {last visited: 2022-04-18}
}
 
 @misc{gym,
  author       = {OpenAI},
  howpublished = {\url{https://gym.openai.com}},
  title        = {Gym},
  urldate      = {2022-04-16},
  note         = {last visited: 2022-04-22}
}



 @misc{keras-rl,
  author       = {Matthias Plappert},
  title        = {keras-rl},
  year         = {2016},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.cdn.hbchan.top/keras-rl/keras-rl}},
  note         = {last visited: 2022-04-22}
}


 @misc{kerasrl2,
  author       = {McNally, Taylor},
  title        = {keras-rl2},
  year         = {2021},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/taylormcnally/keras-rl2}},
  commit       = {06f51537f9066fa72a56c506b589eef4b07644d9},
  note         = {last visited: 2022-04-22}
}

@article{openai,
  title    = {{OpenAI} {Gym}},
  url      = {http://arxiv.org/abs/1606.01540},
  abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software.},
  urldate  = {2022-03-31},
  journal  = {arXiv:1606.01540 [cs]},
  author   = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  month    = jun,
  year     = {2016},
  note     = {arXiv: 1606.01540},
  keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, gym, OpenAi},
  file     = {arXiv Fulltext PDF:/Users/roberto/Zotero/storage/NTAGYJR2/Brockman et al. - 2016 - OpenAI Gym.pdf:application/pdf;arXiv.org Snapshot:/Users/roberto/Zotero/storage/TK3L5PUD/1606.html:text/html}
}

@misc{openai_rl,
  title        = {INTRODUCTION TO RL},
  author       = {OpenAI},
  year         = {2018},
  howpublished = {\url {https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html}},
  note         = {last visited: 2022-03-18}
}

@misc{openairos_2,
  author       = {siw-engineering},
  title        = {openai\_ros2},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{hhttps://github.com/siw-engineering/openai_ros2}},
  commit       = {5083adb9a61cf91b61c6e2f83a921061413ff8be},
  note         = {last visited: 2022-04-18}
}

@misc{parameterimportance,
  title        = {WandB - Parameter Importance},
  author       = {WandB},
  urldate      = {2022-04-16},
  howpublished = {\url{https://docs.wandb.ai/ref/app/features/panels/parameter-importance}},
  note         = {last visited: 2022-04-22}
}
@misc{pygame,
  author        = {Pygame},
  date-modified = {2022-03-09 20:54:46 +0000},
  howpublished  = {\url{https://www.pygame.org}},
  keywords      = {2d, pymunk, physics},
  title         = {Pygame},
  note          = {last visited: 2022-03-30}
}

@misc{pymunk,
  author        = {Pymunk},
  date-modified = {2022-03-09 20:54:46 +0000},
  howpublished  = {\url{http://www.pymunk.org}},
  keywords      = {2d, pymunk, physics},
  title         = {Pymunk},
  note          = {last visited: 2022-03-30}
}

@book{reinforcement_learning,
  title        = {Reinforcement Learning, second edition: An Introduction},
  isbn         = {978-0-262-35270-3},
  abstractnote = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field’s key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning’s relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson’s wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
  note         = {Google-Books-ID: uWV0DwAAQBAJ},
  publisher    = {MIT Press},
  author       = {Sutton, Richard S. and Barto, Andrew G.},
  year         = {2018},
  month        = {Nov}
}

@online{relu,
  author        = {DanB},
  date-added    = {2022-02-28 11:28:52 +0000},
  date-modified = {2022-03-09 10:59:28 +0000},
  keywords      = {activation functions},
  lastchecked   = {15/01/2022},
  read          = {1},
  title         = {Rectified Linear Units (ReLU) in Deep Learning},
  url           = {https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning},
  urldate       = {15/01/2022},
  year          = {2018},
  bdsk-url-1    = {https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning}
}

@misc{Robocup,
  author = {Hiroaki Kitano and Minoru Asada and Yasuo Kuniyoshi and Itsuki Noda and Eiichi Osawa},
  title  = {RoboCup: The Robot World Cup Initiative},
  year   = {1995}
}

@misc{ros-gym,
  author        = {Alberto Ezquerro and Miguel Angel Rodriguez and Ricardo Tellez},
  date-modified = {2022-03-09 20:54:46 +0000},
  howpublished  = {\url{http://wiki.ros.org/openai_ros}},
  keywords      = {ros, openai, gym},
  title         = {openai ros},
  year          = {2016},
  note          = {last visited: 2022-03-20}
}

@misc{wandb,
  title        = {Weights and Biases},
  author       = {WandB},
  howpublished = {\url{https://wandb.ai/site}},
  note         = {last visited: 2022-04-22}
}